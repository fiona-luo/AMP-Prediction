{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import seaborn as sns\n",
    "from math import floor, ceil\n",
    "from pylab import rcParams\n",
    "from sklearn import svm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"AntimicrobialTrainingSequences.csv\"\n",
    "df = pd.read_csv(file_name, low_memory=False)\n",
    "\n",
    "target = \"Antimicrobial\"\n",
    "\n",
    "test_proportion = 0.2\n",
    "bool_target = \"bool_{}\".format(target)\n",
    "\n",
    "col_list = df.columns.where(((df.columns==target).astype(int) + (~df.isnull().any()).astype(int)).astype(bool)).dropna()\n",
    "df = df.loc[:, col_list]\n",
    "\n",
    "features = [\"InterfaceHydrophobicity\",\"OctanolHydrophobicity\",\"GRAVY\",\"TotalCharge\",\\\n",
    "            \"TotalPositiveCharge\",\"TotalNegativeCharge\",\"AveragePositivePosition\",\"AverageNegativePosition\",\\\n",
    "            \"Weight\",\"hmol\",\"hmol_pos\",\"hmol_neg\",\"smol_pos\",\"smol_neg\",\"ave_smol\",\"ave_hmol_pos\",\\\n",
    "            \"ave_hmol_neg\",\"ave_smol_pos\",\"ave_smol_neg\",\"hmol_pos_largest\",\"hmol_neg_largest\",\\\n",
    "            \"hmol_pos_smallest\",\"hmol_neg_smallest\",\"eo_pos\",\"sigma\",\"stericmol_largest\",\"stericmol_smallest\",\\\n",
    "            \"stericatom_largest\",\"stericatom_smallest\"]\n",
    "            \n",
    "df[features] = scaler.fit_transform(df[features].to_numpy())\n",
    "\n",
    "inputX = df[features]\n",
    "test = df.loc[[random.random() < test_proportion for i in range(len(df))],:]\n",
    "train = df.loc[~df.index.isin(test.index),:]\n",
    "train_X = train[features]\n",
    "train_y = train[[\"Antimicrobial\"]]\n",
    "test_X = test[features]\n",
    "test_y = test[[\"Antimicrobial\"]]\n",
    "\n",
    "train_len = len(train)\n",
    "test_len = len(test)\n",
    "\n",
    "num_features = len(train_X.columns)\n",
    "\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(train_X).astype(float)\n",
    "train_y = np.array(train_y).astype(float)\n",
    "test_X = np.array(test_X).astype(float)\n",
    "test_y = np.array(test_y).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "print(train_y.shape)\n",
    "classifier.fit(train_X, train_y) \n",
    "\"\"\"\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "init = keras.initializers.RandomUniform(-1, 1)\n",
    "\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(16, activation='relu', kernel_initializer=init, input_dim=len(features)))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the neural network\n",
    "adam = optimizers.Adam(lr=0.001)\n",
    "classifier.compile(optimizer =adam,loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the data to the training dataset\n",
    "history = classifier.fit(train_X,train_y, batch_size=400, epochs=400,validation_data=(test_X,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_model=classifier.evaluate(train_X, train_y)\n",
    "eval_model\n",
    "# loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_model=classifier.evaluate(test_X, test_y)\n",
    "eval_model\n",
    "# loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred=classifier.predict(test_X)\n",
    "y_pred =(y_pred>0.5)\n",
    "y_pred1=classifier.predict(train_X)\n",
    "y_pred1 =(y_pred1>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics on model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm1 = confusion_matrix(train_y, y_pred1)\n",
    "cm = confusion_matrix(test_y, y_pred)\n",
    "print(\"Training data\")\n",
    "print(cm1)\n",
    "print(\"Testing data\")\n",
    "print(cm)\n",
    "\n",
    "# TN FP <- should be negative\n",
    "# FN TP <- should be positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp1 = cm1[1][1]\n",
    "fp1 = cm1[0][1]\n",
    "tn1 = cm1[0][0]\n",
    "fn1 = cm1[1][0]\n",
    "\n",
    "F1a = tp1 / (tp1 + fp1)\n",
    "acc1 = (tp1 + tn1)/(tp1+fp1+tn1+fn1)\n",
    "sens1 = tp1 / (tp1 + fn1)\n",
    "sens1 = tp1 / (tp1 + fn1) \n",
    "spec1 = tn1 / (tn1 + fp1) \n",
    "mcc1 = (tp1*tn1-fp1*fn1)/math.sqrt((tp1+fp1)*(tp1+fn1)*(tn1+fp1)*(tn1+fn1))\n",
    "pretestProb1 = (tp1 + fn1)/(tp1+fp1+tn1+fn1)\n",
    "print()\n",
    "print(\"Training data\")\n",
    "print(\"acc:\", acc1)\n",
    "print(\"F1:\",F1a)\n",
    "print(\"sens:\",sens1)\n",
    "print(\"spec:\",spec1)\n",
    "print(\"mcc:\",mcc1)\n",
    "print(\"pretestProb:\",pretestProb1)\n",
    "\n",
    "\n",
    "tp = cm[1][1]\n",
    "fp = cm[0][1]\n",
    "tn = cm[0][0]\n",
    "fn = cm[1][0]\n",
    "\n",
    "acc = (tp + tn)/(tp+fp+tn+fn) \n",
    "F1 = tp / (tp + fp) \n",
    "sens = tp / (tp + fn) \n",
    "spec = tn / (tn + fp) \n",
    "mcc = (tp*tn-fp*fn)/math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)) \n",
    "pretestProb = (tp + fn)/(tp+fp+tn+fn)\n",
    "print()\n",
    "print(\"Testing data\")\n",
    "print(\"acc:\", acc)\n",
    "print(\"F1:\",F1)\n",
    "print(\"sens:\",sens)\n",
    "print(\"spec:\",spec)\n",
    "print(\"mcc:\",mcc)\n",
    "print(\"pretestProb:\",pretestProb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
